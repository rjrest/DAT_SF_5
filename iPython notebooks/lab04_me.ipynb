{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ML algorithms in python\n",
      "\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# keep is simple, load a default dataset\n",
      "\n",
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from the datasets load the iris data into a variable called iris\n",
      "\n",
      "iris = datasets.load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# what does iris look like?\n",
      "type(iris)\n",
      "#iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "sklearn.datasets.base.Bunch"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "{'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
        " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
        "       [ 4.9,  3. ,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.3,  0.2],\n",
        "       [ 4.6,  3.1,  1.5,  0.2],\n",
        "       [ 5. ,  3.6,  1.4,  0.2],\n",
        "       [ 5.4,  3.9,  1.7,  0.4],\n",
        "       [ 4.6,  3.4,  1.4,  0.3],\n",
        "       [ 5. ,  3.4,  1.5,  0.2],\n",
        "       [ 4.4,  2.9,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5.4,  3.7,  1.5,  0.2],\n",
        "       [ 4.8,  3.4,  1.6,  0.2],\n",
        "       [ 4.8,  3. ,  1.4,  0.1],\n",
        "       [ 4.3,  3. ,  1.1,  0.1],\n",
        "       [ 5.8,  4. ,  1.2,  0.2],\n",
        "       [ 5.7,  4.4,  1.5,  0.4],\n",
        "       [ 5.4,  3.9,  1.3,  0.4],\n",
        "       [ 5.1,  3.5,  1.4,  0.3],\n",
        "       [ 5.7,  3.8,  1.7,  0.3],\n",
        "       [ 5.1,  3.8,  1.5,  0.3],\n",
        "       [ 5.4,  3.4,  1.7,  0.2],\n",
        "       [ 5.1,  3.7,  1.5,  0.4],\n",
        "       [ 4.6,  3.6,  1. ,  0.2],\n",
        "       [ 5.1,  3.3,  1.7,  0.5],\n",
        "       [ 4.8,  3.4,  1.9,  0.2],\n",
        "       [ 5. ,  3. ,  1.6,  0.2],\n",
        "       [ 5. ,  3.4,  1.6,  0.4],\n",
        "       [ 5.2,  3.5,  1.5,  0.2],\n",
        "       [ 5.2,  3.4,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.6,  0.2],\n",
        "       [ 4.8,  3.1,  1.6,  0.2],\n",
        "       [ 5.4,  3.4,  1.5,  0.4],\n",
        "       [ 5.2,  4.1,  1.5,  0.1],\n",
        "       [ 5.5,  4.2,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5. ,  3.2,  1.2,  0.2],\n",
        "       [ 5.5,  3.5,  1.3,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 4.4,  3. ,  1.3,  0.2],\n",
        "       [ 5.1,  3.4,  1.5,  0.2],\n",
        "       [ 5. ,  3.5,  1.3,  0.3],\n",
        "       [ 4.5,  2.3,  1.3,  0.3],\n",
        "       [ 4.4,  3.2,  1.3,  0.2],\n",
        "       [ 5. ,  3.5,  1.6,  0.6],\n",
        "       [ 5.1,  3.8,  1.9,  0.4],\n",
        "       [ 4.8,  3. ,  1.4,  0.3],\n",
        "       [ 5.1,  3.8,  1.6,  0.2],\n",
        "       [ 4.6,  3.2,  1.4,  0.2],\n",
        "       [ 5.3,  3.7,  1.5,  0.2],\n",
        "       [ 5. ,  3.3,  1.4,  0.2],\n",
        "       [ 7. ,  3.2,  4.7,  1.4],\n",
        "       [ 6.4,  3.2,  4.5,  1.5],\n",
        "       [ 6.9,  3.1,  4.9,  1.5],\n",
        "       [ 5.5,  2.3,  4. ,  1.3],\n",
        "       [ 6.5,  2.8,  4.6,  1.5],\n",
        "       [ 5.7,  2.8,  4.5,  1.3],\n",
        "       [ 6.3,  3.3,  4.7,  1.6],\n",
        "       [ 4.9,  2.4,  3.3,  1. ],\n",
        "       [ 6.6,  2.9,  4.6,  1.3],\n",
        "       [ 5.2,  2.7,  3.9,  1.4],\n",
        "       [ 5. ,  2. ,  3.5,  1. ],\n",
        "       [ 5.9,  3. ,  4.2,  1.5],\n",
        "       [ 6. ,  2.2,  4. ,  1. ],\n",
        "       [ 6.1,  2.9,  4.7,  1.4],\n",
        "       [ 5.6,  2.9,  3.6,  1.3],\n",
        "       [ 6.7,  3.1,  4.4,  1.4],\n",
        "       [ 5.6,  3. ,  4.5,  1.5],\n",
        "       [ 5.8,  2.7,  4.1,  1. ],\n",
        "       [ 6.2,  2.2,  4.5,  1.5],\n",
        "       [ 5.6,  2.5,  3.9,  1.1],\n",
        "       [ 5.9,  3.2,  4.8,  1.8],\n",
        "       [ 6.1,  2.8,  4. ,  1.3],\n",
        "       [ 6.3,  2.5,  4.9,  1.5],\n",
        "       [ 6.1,  2.8,  4.7,  1.2],\n",
        "       [ 6.4,  2.9,  4.3,  1.3],\n",
        "       [ 6.6,  3. ,  4.4,  1.4],\n",
        "       [ 6.8,  2.8,  4.8,  1.4],\n",
        "       [ 6.7,  3. ,  5. ,  1.7],\n",
        "       [ 6. ,  2.9,  4.5,  1.5],\n",
        "       [ 5.7,  2.6,  3.5,  1. ],\n",
        "       [ 5.5,  2.4,  3.8,  1.1],\n",
        "       [ 5.5,  2.4,  3.7,  1. ],\n",
        "       [ 5.8,  2.7,  3.9,  1.2],\n",
        "       [ 6. ,  2.7,  5.1,  1.6],\n",
        "       [ 5.4,  3. ,  4.5,  1.5],\n",
        "       [ 6. ,  3.4,  4.5,  1.6],\n",
        "       [ 6.7,  3.1,  4.7,  1.5],\n",
        "       [ 6.3,  2.3,  4.4,  1.3],\n",
        "       [ 5.6,  3. ,  4.1,  1.3],\n",
        "       [ 5.5,  2.5,  4. ,  1.3],\n",
        "       [ 5.5,  2.6,  4.4,  1.2],\n",
        "       [ 6.1,  3. ,  4.6,  1.4],\n",
        "       [ 5.8,  2.6,  4. ,  1.2],\n",
        "       [ 5. ,  2.3,  3.3,  1. ],\n",
        "       [ 5.6,  2.7,  4.2,  1.3],\n",
        "       [ 5.7,  3. ,  4.2,  1.2],\n",
        "       [ 5.7,  2.9,  4.2,  1.3],\n",
        "       [ 6.2,  2.9,  4.3,  1.3],\n",
        "       [ 5.1,  2.5,  3. ,  1.1],\n",
        "       [ 5.7,  2.8,  4.1,  1.3],\n",
        "       [ 6.3,  3.3,  6. ,  2.5],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 7.1,  3. ,  5.9,  2.1],\n",
        "       [ 6.3,  2.9,  5.6,  1.8],\n",
        "       [ 6.5,  3. ,  5.8,  2.2],\n",
        "       [ 7.6,  3. ,  6.6,  2.1],\n",
        "       [ 4.9,  2.5,  4.5,  1.7],\n",
        "       [ 7.3,  2.9,  6.3,  1.8],\n",
        "       [ 6.7,  2.5,  5.8,  1.8],\n",
        "       [ 7.2,  3.6,  6.1,  2.5],\n",
        "       [ 6.5,  3.2,  5.1,  2. ],\n",
        "       [ 6.4,  2.7,  5.3,  1.9],\n",
        "       [ 6.8,  3. ,  5.5,  2.1],\n",
        "       [ 5.7,  2.5,  5. ,  2. ],\n",
        "       [ 5.8,  2.8,  5.1,  2.4],\n",
        "       [ 6.4,  3.2,  5.3,  2.3],\n",
        "       [ 6.5,  3. ,  5.5,  1.8],\n",
        "       [ 7.7,  3.8,  6.7,  2.2],\n",
        "       [ 7.7,  2.6,  6.9,  2.3],\n",
        "       [ 6. ,  2.2,  5. ,  1.5],\n",
        "       [ 6.9,  3.2,  5.7,  2.3],\n",
        "       [ 5.6,  2.8,  4.9,  2. ],\n",
        "       [ 7.7,  2.8,  6.7,  2. ],\n",
        "       [ 6.3,  2.7,  4.9,  1.8],\n",
        "       [ 6.7,  3.3,  5.7,  2.1],\n",
        "       [ 7.2,  3.2,  6. ,  1.8],\n",
        "       [ 6.2,  2.8,  4.8,  1.8],\n",
        "       [ 6.1,  3. ,  4.9,  1.8],\n",
        "       [ 6.4,  2.8,  5.6,  2.1],\n",
        "       [ 7.2,  3. ,  5.8,  1.6],\n",
        "       [ 7.4,  2.8,  6.1,  1.9],\n",
        "       [ 7.9,  3.8,  6.4,  2. ],\n",
        "       [ 6.4,  2.8,  5.6,  2.2],\n",
        "       [ 6.3,  2.8,  5.1,  1.5],\n",
        "       [ 6.1,  2.6,  5.6,  1.4],\n",
        "       [ 7.7,  3. ,  6.1,  2.3],\n",
        "       [ 6.3,  3.4,  5.6,  2.4],\n",
        "       [ 6.4,  3.1,  5.5,  1.8],\n",
        "       [ 6. ,  3. ,  4.8,  1.8],\n",
        "       [ 6.9,  3.1,  5.4,  2.1],\n",
        "       [ 6.7,  3.1,  5.6,  2.4],\n",
        "       [ 6.9,  3.1,  5.1,  2.3],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 6.8,  3.2,  5.9,  2.3],\n",
        "       [ 6.7,  3.3,  5.7,  2.5],\n",
        "       [ 6.7,  3. ,  5.2,  2.3],\n",
        "       [ 6.3,  2.5,  5. ,  1.9],\n",
        "       [ 6.5,  3. ,  5.2,  2. ],\n",
        "       [ 6.2,  3.4,  5.4,  2.3],\n",
        "       [ 5.9,  3. ,  5.1,  1.8]]),\n",
        " 'feature_names': ['sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'],\n",
        " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
        " 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
        "      dtype='|S10')}"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Now to display it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "from matplotlib.ticker import MultipleLocator, FormatStrFormatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data with load_iris from sklearn\n",
      "\n",
      "X = iris['data']\n",
      "Names = iris['feature_names']\n",
      "y = iris['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 5.1  3.5  1.4  0.2]\n",
        " [ 4.9  3.   1.4  0.2]\n",
        " [ 4.7  3.2  1.3  0.2]\n",
        " [ 4.6  3.1  1.5  0.2]\n",
        " [ 5.   3.6  1.4  0.2]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate the top-level figure for this plot\n",
      "fig = plt.figure(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate our six subplots. Note that context will be set to\n",
      "ax1 = fig.add_subplot(2,3,1)\n",
      "ax2 = fig.add_subplot(2,3,2)\n",
      "ax3 = fig.add_subplot(2,3,3)\n",
      "ax4 = fig.add_subplot(2,3,4)\n",
      "ax5 = fig.add_subplot(2,3,5)\n",
      "ax6 = fig.add_subplot(2,3,6)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Title the figure\n",
      "\n",
      "fig.suptitle('Subplots demo with Iris Data', fontsize = 14)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "<matplotlib.text.Text at 0x108be29d0>"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set the number of decimal places to 1 (float) in y-axis labels\n",
      "majorFormatter = FormatStrFormatter('%1.1f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(majorFormatter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "matplotlib.ticker.FormatStrFormatter"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loop thru subplots and set font size\n",
      "# HINT: 'plt.gcf().axes' gets all axes for get-current-figure\n",
      "\n",
      "all_axes = plt.gcf().axes\n",
      "for ax in all_axes:\n",
      "    ax.yaxis.set_major_formatter(majorFormatter)                       # set the y-ax to 1 decimal format\n",
      "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():      # then for both x & y axes,\n",
      "        ticklabel.set_fontsize(6)                                      # set the font size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot and format the 1st subplot\n",
      "\n",
      "for t, marker, c in zip(xrange(3), \">ox\", \"rgb\"):             # zip means create a tuple:  ( 0, >, r)  (1, o, g)  (2, x, b)\n",
      "    # plot each class on its own to get diff color markers\n",
      "    ax1.scatter(X[y == t, 0],\n",
      "                X[y == t, 1],\n",
      "                marker = marker,\n",
      "                c = c)\n",
      "    ax1.set_xlabel(Names[0], fontsize=8)\n",
      "    ax1.set_ylabel(Names[1], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot and format the 2nd subplot\n",
      "\n",
      "for t, marker, c in zip(xrange(3), \">ox\", \"rgb\"):             # zip means create a tuple:  ( 0, >, r)  (1, o, g)  (2, x, b)\n",
      "    # plot each class on its own to get diff color markers\n",
      "    ax2.scatter(X[y == t, 0],\n",
      "                X[y == t, 2],\n",
      "                marker = marker,\n",
      "                c = c)\n",
      "    ax2.set_xlabel(Names[0], fontsize=8)\n",
      "    ax2.set_ylabel(Names[2], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot and format the 3rd subplot\n",
      "\n",
      "for t, marker, c in zip(xrange(3), \">ox\", \"rgb\"):             # zip means create a tuple:  ( 0, >, r)  (1, o, g)  (2, x, b)\n",
      "    # plot each class on its own to get diff color markers\n",
      "    ax3.scatter(X[y == t, 0],\n",
      "                X[y == t, 3],\n",
      "                marker = marker,\n",
      "                c = c)\n",
      "    ax3.set_xlabel(Names[0], fontsize=8)\n",
      "    ax3.set_ylabel(Names[3], fontsize=8)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "# plot and format the 4th subplot\n",
      "for t, marker, c in zip(xrange(3), \">ox\", \"rgb\"):             # zip means create a tuple:  ( 0, >, r)  (1, o, g)  (2, x, b)\n",
      "    # plot each class on its own to get diff color markers\n",
      "    ax4.scatter(X[y == t, 1],\n",
      "                X[y == t, 2],\n",
      "                marker = marker,\n",
      "                c = c)\n",
      "    ax4.set_xlabel(Names[1], fontsize=8)\n",
      "    ax4.set_ylabel(Names[2], fontsize=8)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "# plot and format the 5th subplot\n",
      "for t, marker, c in zip(xrange(3), \">ox\", \"rgb\"):             # zip means create a tuple:  ( 0, >, r)  (1, o, g)  (2, x, b)\n",
      "    # plot each class on its own to get diff color markers\n",
      "    ax5.scatter(X[y == t, 1],\n",
      "                X[y == t, 3],\n",
      "                marker = marker,\n",
      "                c = c)\n",
      "    ax5.set_xlabel(Names[1], fontsize=8)\n",
      "    ax5.set_ylabel(Names[3], fontsize=8)\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "# plot and format the 6th subplot\n",
      "for t, marker, c in zip(xrange(3), \">ox\", \"rgb\"):             # zip means create a tuple:  ( 0, >, r)  (1, o, g)  (2, x, b)\n",
      "    # plot each class on its own to get diff color markers\n",
      "    ax6.scatter(X[y == t, 2],\n",
      "                X[y == t, 3],\n",
      "                marker = marker,\n",
      "                c = c)\n",
      "    ax6.set_xlabel(Names[2], fontsize=8)\n",
      "    ax6.set_ylabel(Names[3], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save the figure with subplots as a file on disk (optional)\n",
      "plt.savefig('lab04_me_iris_plot_combined.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lets try something else"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lets use Pandas\n",
      "\n",
      "df = pd.DataFrame(data=X, columns= ['SepalLength','SepalWidth','PetalLength','PetalWidth'])\n",
      "df['Target'] = y                     # add new columns just by naming them and ingesting data for it\n",
      "df['Name'] = iris.target_names[y]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "      <th>Target</th>\n",
        "      <th>Name</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>145</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.2</td>\n",
        "      <td> 2.3</td>\n",
        "      <td> 2</td>\n",
        "      <td> virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>146</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 2.5</td>\n",
        "      <td> 5.0</td>\n",
        "      <td> 1.9</td>\n",
        "      <td> 2</td>\n",
        "      <td> virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>147</th>\n",
        "      <td> 6.5</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.2</td>\n",
        "      <td> 2.0</td>\n",
        "      <td> 2</td>\n",
        "      <td> virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>148</th>\n",
        "      <td> 6.2</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 5.4</td>\n",
        "      <td> 2.3</td>\n",
        "      <td> 2</td>\n",
        "      <td> virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149</th>\n",
        "      <td> 5.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.1</td>\n",
        "      <td> 1.8</td>\n",
        "      <td> 2</td>\n",
        "      <td> virginica</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "     SepalLength  SepalWidth  PetalLength  PetalWidth  Target       Name\n",
        "145          6.7         3.0          5.2         2.3       2  virginica\n",
        "146          6.3         2.5          5.0         1.9       2  virginica\n",
        "147          6.5         3.0          5.2         2.0       2  virginica\n",
        "148          6.2         3.4          5.4         2.3       2  virginica\n",
        "149          5.9         3.0          5.1         1.8       2  virginica\n",
        "\n",
        "[5 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Homework: find the functions to do the same plots but with referencing the Pandas dataframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# KNN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's re-assign the data to standard named variables\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "Names = iris.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the data into a training and test set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# is there a function to do that in sklearn?\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)  #random seed at a fixed position\n",
      "\n",
      "# remember that X is an array with LOTs of features\n",
      "# y is an array with the same number of records as X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train KNN classifier defined function on the train data\n",
      "\n",
      "myknn = KNeighborsClassifier(3).fit(X_train,y_train)    # 3 is the number of neighbors to use"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For kicks let's try it with inverse-distance weighted, not jsut majority rules\n",
      "# http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "150"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generic cross validation fn\n",
      "\n",
      "def my_cross_validate(X, y, classifier, k_fold) :\n",
      "    # k_fold is the number of folds I want.\n",
      "    \n",
      "    #derice a set of (random) training & test indices\n",
      "    k_fold_indices = KFold( len(X), n_folds=k_fold, indices=True, shuffle=True, random_state=0)\n",
      "    \n",
      "    k_score_total = 0\n",
      "    # for each train and test slice, run the classifier, and score the result\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "        \n",
      "        model = classifier(X[[ train_slice  ]],\n",
      "                           y[[ train_slice ]])\n",
      "        \n",
      "        k_score = model.score(X[[ test_slice ]],\n",
      "                              y[[ test_slice ]])\n",
      "        \n",
      "        k_score_total += k_score\n",
      "        \n",
      "    # return the average accuracy having scored on the test slice over all folds\n",
      "    return k_score_total / k_fold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now lets try out that function I made\n",
      "# let's do a 10-fold cross validation, on KNN fit, of the iris dataset\n",
      "\n",
      "\n",
      "my_cross_validate(X, y, KNeighborsClassifier(3).fit, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "0.95999999999999996"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "# Or, we can use the function SKLearn already has :)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, ShuffleSplit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples = len(y)\n",
      "knn = KNeighborsClassifier(3)\n",
      "cv = ShuffleSplit(n_samples, n_iter=10, test_size=0.3, random_state=0)\n",
      "\n",
      "test_scores = cross_val_score( knn, X, y, cv=cv)\n",
      "test_scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "# Or, the more explicit way to do cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples = len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "150"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
        " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
        " 2 2]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "# see what ShuffleSplit returns:  http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.ShuffleSplit.html\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1,\n",
      "    random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print enumerate(cv)    # see what enumerate does:  http://docs.python.org/2.7/library/functions.html#enumerate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<enumerate object at 0x105c22c30>\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(enumerate(cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "[(0,\n",
        "  (array([ 37,  78,  90,  45,  16, 121,  66,  24,   8, 126,  22,  44,  97,\n",
        "        93,  26, 137,  84,  27, 127, 132,  59,  18,  83,  61,  92, 112,\n",
        "         2, 141,  43,  10,  60, 116, 144, 119, 108,  69, 135,  56,  80,\n",
        "       123, 133, 106, 146,  50, 147,  85,  30, 101,  94,  64,  89,  91,\n",
        "       125,  48,  13, 111,  95,  20,  15,  52,   3, 149,  98,   6,  68,\n",
        "       109,  96,  12, 102, 120, 104, 128,  46,  11, 110, 124,  41, 148,\n",
        "         1, 113, 139,  42,   4, 129,  17,  38,   5,  53, 143, 105,   0,\n",
        "        34,  28,  55,  75,  35,  23,  74,  31, 118,  57, 131,  65,  32,\n",
        "       138,  14, 122,  19,  29, 130,  49, 136,  99,  82,  79, 115, 145,\n",
        "        72,  77,  25,  81, 140, 142,  39,  58,  88,  70,  87,  36,  21,\n",
        "         9, 103,  67, 117,  47]),\n",
        "   array([114,  62,  33, 107,   7, 100,  40,  86,  76,  71, 134,  51,  73,\n",
        "        54,  63]))),\n",
        " (1,\n",
        "  (array([148,   6,  65,  47,  68,  60,  15, 124,  58, 142,  12,  59, 105,\n",
        "        89,  78,  52, 131, 113,  98,  30, 136,  66, 133,  49,  62,  74,\n",
        "        17, 106,   8, 135,  80, 107,  90,   0,  36, 112,   5,  57, 102,\n",
        "        55,  34, 128,  33,  21,  73,   7,  45, 129, 103, 146, 120,  94,\n",
        "        50, 134,  99, 126, 114,   9,  39,  97, 101,  29,  81,  20,  46,\n",
        "        51,  53,  23,  27,   2,  28,  37, 111,  10,  84, 137, 127,  43,\n",
        "        87,  69, 144, 140,  35,  76,   3,  82, 145, 116,  88,  44, 147,\n",
        "         1,  93,  38,  11, 115,  54,  40,  18,  41,  79,  24,  56,  71,\n",
        "        13,  31,  85,  70, 132, 125, 123, 100,  32, 104,  83, 117, 118,\n",
        "       138,  25, 110,  16,  75, 109, 121,  86, 139,   4,  96,  14,  61,\n",
        "        67, 149,  95,  19,  72]),\n",
        "   array([ 92, 141, 130, 119,  48, 143, 122,  63,  26,  64,  42, 108,  91,\n",
        "        77,  22]))),\n",
        " (2,\n",
        "  (array([ 62,  76,  69,  46, 129,   1,  10,   3,  95,  21,  41,  57,  47,\n",
        "        78,  19, 107,  90,   9, 147, 148,  40,  29,  27,  89,  37,  33,\n",
        "        84,  54,  88,  73, 111, 125, 101, 143,  23, 117,  50, 146,   2,\n",
        "       110, 118, 131,  17,   6, 127,  67, 124,  15,  56, 115, 112,  71,\n",
        "       145, 100,  38,  80, 109,  44, 144, 130,  35,  97,  59,  48, 134,\n",
        "        70,  65,  98, 138,  55,  43, 132, 103,  30, 114,  34,  18, 141,\n",
        "       139,  49,  52,  74,  26,  45, 126,  39,   4,  11,  53, 149,  79,\n",
        "         8,   0,   5, 133,  61, 135,   7,  83,  99,  22,  68,  82,  20,\n",
        "        28,  86,  14,  42,  32,  25,  36,  92,  75,  64, 142, 120,  81,\n",
        "        58,  13, 140,  72,  87, 123,  93,  91, 136,  51, 116,  24,  94,\n",
        "       106,  16,  63, 128, 105]),\n",
        "   array([ 85, 137,  77, 108, 122, 104, 121,  12,  31,  96, 113, 102,  60,\n",
        "        66, 119])))]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for cv_index, (train, test) in enumerate(cv):\n",
      "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))\n",
      "    \n",
      "    myknn = KNeighborsClassifier(3).fit(X[train], y[train])\n",
      "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
      "        myknn.score(X[train], y[train]), myknn.score(X[test], y[test])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Cross Validation Iteration #0\n",
        "train indices: [ 37  78  90  45  16 121  66  24   8 126]...\n",
        "test indices: [114  62  33 107   7 100  40  86  76  71]...\n",
        "train score: 0.956, test score: 1.000\n",
        "\n",
        "# Cross Validation Iteration #1\n",
        "train indices: [148   6  65  47  68  60  15 124  58 142]...\n",
        "test indices: [ 92 141 130 119  48 143 122  63  26  64]...\n",
        "train score: 0.963, test score: 0.933\n",
        "\n",
        "# Cross Validation Iteration #2\n",
        "train indices: [ 62  76  69  46 129   1  10   3  95  21]...\n",
        "test indices: [ 85 137  77 108 122 104 121  12  31  96]...\n",
        "train score: 0.963, test score: 0.933\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}