{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Implement KNN classification, using the sklearn package. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from matplotlib import pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# thru some frustrating trial & error, got this read in as floats and name the columns\n",
      "\n",
      "data = pd.read_csv('data/iris_data.csv', header=None, dtype={0 : np.float, 1 : np.float, \\\n",
      "                                                             2 : np.float, 3 : np.float, \\\n",
      "                                                             4 : np.str},\\\n",
      "                   names=['SepalLength','SepalWidth','PetalLength','PetalWidth','Name'])\n",
      "data.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "      <th>Name</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
        "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
        "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
        "\n",
        "[2 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Data munging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data[0:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
        "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
        "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
        "\n",
        "[2 rows x 5 columns]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 151 entries, 0 to 150\n",
        "Data columns (total 5 columns):\n",
        "SepalLength    150 non-null float64\n",
        "SepalWidth     150 non-null float64\n",
        "PetalLength    150 non-null float64\n",
        "PetalWidth     150 non-null float64\n",
        "Name           150 non-null object\n",
        "dtypes: float64(4), object(1)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(data.Name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array(['nan', 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], \n",
        "      dtype='|S15')"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Huh? which has a nan?\n",
      "\n",
      "print data[data.Name == np.nan][0::]\n",
      "# print data[data.SepalLength == 5.1][0::]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty DataFrame\n",
        "Columns: [SepalLength, SepalWidth, PetalLength, PetalWidth, Name]\n",
        "Index: []\n",
        "\n",
        "[0 rows x 5 columns]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I dont really understand which index this value is sitting, but\n",
      "# try to drop the row missing data\n",
      "data = data.dropna(axis=0, how='any')\n",
      "data.info()\n",
      "# unique(data['Name'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 150 entries, 0 to 149\n",
        "Data columns (total 5 columns):\n",
        "SepalLength    150 non-null float64\n",
        "SepalWidth     150 non-null float64\n",
        "PetalLength    150 non-null float64\n",
        "PetalWidth     150 non-null float64\n",
        "Name           150 non-null object\n",
        "dtypes: float64(4), object(1)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test again: what Labels do I have now?\n",
      "np.unique(data['Name'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], \n",
        "      dtype='|S15')"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Okay, clean data now.\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "# I want a numerical label to use KNN, not a string. Need to create a column with a numerical label 0,1,2 -- corresponding to string Name"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how does enumerate work again?\n",
      "\n",
      "list(enumerate(np.unique(data['Name'])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[(0, 'Iris-setosa'), (1, 'Iris-versicolor'), (2, 'Iris-virginica')]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up a dictionary of Names : numerical index\n",
      "labels_dict = { name : i for i, name in list(enumerate(np.unique(data['Name']))) }\n",
      "    \n",
      "labels_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_dict['Iris-setosa']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Label'] = data['Name'].map(lambda x: labels_dict[x])\n",
      "data[0:149:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "      <th>Name</th>\n",
        "      <th>Label</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td>     Iris-setosa</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20 </th>\n",
        "      <td> 5.4</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.7</td>\n",
        "      <td> 0.2</td>\n",
        "      <td>     Iris-setosa</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40 </th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.3</td>\n",
        "      <td>     Iris-setosa</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>60 </th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 2.0</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.0</td>\n",
        "      <td> Iris-versicolor</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>80 </th>\n",
        "      <td> 5.5</td>\n",
        "      <td> 2.4</td>\n",
        "      <td> 3.8</td>\n",
        "      <td> 1.1</td>\n",
        "      <td> Iris-versicolor</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>100</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 3.3</td>\n",
        "      <td> 6.0</td>\n",
        "      <td> 2.5</td>\n",
        "      <td>  Iris-virginica</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>120</th>\n",
        "      <td> 6.9</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 5.7</td>\n",
        "      <td> 2.3</td>\n",
        "      <td>  Iris-virginica</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>140</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> 2.4</td>\n",
        "      <td>  Iris-virginica</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "     SepalLength  SepalWidth  PetalLength  PetalWidth             Name  Label\n",
        "0            5.1         3.5          1.4         0.2      Iris-setosa      0\n",
        "20           5.4         3.4          1.7         0.2      Iris-setosa      0\n",
        "40           5.0         3.5          1.3         0.3      Iris-setosa      0\n",
        "60           5.0         2.0          3.5         1.0  Iris-versicolor      1\n",
        "80           5.5         2.4          3.8         1.1  Iris-versicolor      1\n",
        "100          6.3         3.3          6.0         2.5   Iris-virginica      2\n",
        "120          6.9         3.2          5.7         2.3   Iris-virginica      2\n",
        "140          6.7         3.1          5.6         2.4   Iris-virginica      2\n",
        "\n",
        "[8 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Onto KNN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xfeatures = data[['SepalLength','SepalWidth','PetalLength','PetalWidth']]\n",
      "ysolutions = data['Label']\n",
      "\n",
      "print Xfeatures.shape, ysolutions.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(150, 4) (150,)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a training/test split in my data\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split( Xfeatures, ysolutions,\\\n",
      "                                                     test_size=0.33,\\\n",
      "                                                     random_state=156)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train the KNN classifier function on the training data\n",
      "\n",
      "myknn = KNeighborsClassifier(5).fit(X_train, y_train)    # 5 nearest neighbors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# score it on test set.\n",
      "\n",
      "myknn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0.95999999999999996"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For kicks let's try it with inverse-distance weighted, not jsut majority rules\n",
      "# http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn_weighted = KNeighborsClassifier(5, weights='distance').fit(X_train, y_train)\n",
      "myknn_weighted.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "0.95999999999999996"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Implement cross-validation for your KNN classifier."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "You may find it helpful to start with the cross-validation code from the lab. Note that you may need to re- write portions of that code to get it to work for you. Use 5 folds for your cross- validation. Do NOT use the cross_val_score method from sklearn to do this \u201cblack box\u201d for you."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let me explore a bit more what KFold actually returns.\n",
      "# Okay, so it gives me pairs of arrays: \n",
      "# first: the indices of a full training set with n-1 folds, second: indices for a test with 1 fold\n",
      "# ... and it gives me n pairs of these.\n",
      "\n",
      "list(KFold( len(Xfeatures), 5, indices=True, shuffle=True, random_state=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[(array([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "        15,  17,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  30,\n",
        "        32,  34,  36,  37,  38,  39,  41,  43,  45,  46,  47,  48,  49,\n",
        "        50,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,\n",
        "        65,  67,  68,  69,  70,  71,  72,  74,  76,  79,  80,  81,  82,\n",
        "        83,  85,  86,  87,  88,  89,  91,  93,  95,  96,  97, 100, 101,\n",
        "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
        "       116, 117, 118, 119, 121, 122, 123, 124, 126, 127, 128, 129, 130,\n",
        "       132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145,\n",
        "       147, 148, 149]),\n",
        "  array([  5,  14,  16,  19,  29,  31,  33,  35,  40,  42,  44,  51,  56,\n",
        "        66,  73,  75,  77,  78,  84,  90,  92,  94,  98,  99, 102, 120,\n",
        "       125, 131, 141, 146])),\n",
        " (array([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "        14,  15,  16,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,\n",
        "        30,  31,  32,  33,  34,  35,  37,  38,  40,  41,  42,  43,  44,\n",
        "        46,  47,  49,  50,  51,  52,  55,  56,  57,  60,  61,  62,  63,\n",
        "        64,  65,  66,  67,  68,  70,  71,  72,  73,  74,  75,  76,  77,\n",
        "        78,  79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  92,\n",
        "        93,  94,  96,  97,  98,  99, 100, 101, 102, 104, 105, 106, 109,\n",
        "       110, 111, 113, 115, 116, 120, 121, 123, 124, 125, 127, 129, 130,\n",
        "       131, 133, 134, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146,\n",
        "       147, 148, 149]),\n",
        "  array([  4,  17,  18,  28,  36,  39,  45,  48,  53,  54,  58,  59,  69,\n",
        "        85,  91,  95, 103, 107, 108, 112, 114, 117, 118, 119, 122, 126,\n",
        "       128, 132, 135, 139])),\n",
        " (array([  0,   1,   3,   4,   5,   7,   8,   9,  13,  14,  15,  16,  17,\n",
        "        18,  19,  20,  21,  22,  24,  25,  26,  28,  29,  30,  31,  33,\n",
        "        35,  36,  37,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,\n",
        "        50,  51,  52,  53,  54,  56,  57,  58,  59,  60,  61,  63,  64,\n",
        "        66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,  79,\n",
        "        80,  81,  82,  84,  85,  86,  87,  88,  90,  91,  92,  94,  95,\n",
        "        96,  97,  98,  99, 101, 102, 103, 105, 106, 107, 108, 109, 112,\n",
        "       114, 115, 117, 118, 119, 120, 121, 122, 125, 126, 128, 129, 130,\n",
        "       131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 145,\n",
        "       146, 147, 148]),\n",
        "  array([  2,   6,  10,  11,  12,  23,  27,  32,  34,  38,  46,  55,  62,\n",
        "        65,  74,  83,  89,  93, 100, 104, 110, 111, 113, 116, 123, 124,\n",
        "       127, 138, 144, 149])),\n",
        " (array([  0,   1,   2,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,\n",
        "        16,  17,  18,  19,  20,  22,  23,  25,  27,  28,  29,  31,  32,\n",
        "        33,  34,  35,  36,  37,  38,  39,  40,  42,  44,  45,  46,  47,\n",
        "        48,  50,  51,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
        "        63,  65,  66,  68,  69,  71,  72,  73,  74,  75,  77,  78,  79,\n",
        "        81,  83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,  95,\n",
        "        96,  98,  99, 100, 101, 102, 103, 104, 107, 108, 110, 111, 112,\n",
        "       113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126,\n",
        "       127, 128, 129, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141,\n",
        "       144, 146, 149]),\n",
        "  array([  3,   9,  15,  21,  24,  26,  30,  41,  43,  49,  52,  64,  67,\n",
        "        70,  76,  80,  82,  87,  97, 105, 106, 109, 121, 130, 136, 142,\n",
        "       143, 145, 147, 148])),\n",
        " (array([  2,   3,   4,   5,   6,   9,  10,  11,  12,  14,  15,  16,  17,\n",
        "        18,  19,  21,  23,  24,  26,  27,  28,  29,  30,  31,  32,  33,\n",
        "        34,  35,  36,  38,  39,  40,  41,  42,  43,  44,  45,  46,  48,\n",
        "        49,  51,  52,  53,  54,  55,  56,  58,  59,  62,  64,  65,  66,\n",
        "        67,  69,  70,  73,  74,  75,  76,  77,  78,  80,  82,  83,  84,\n",
        "        85,  87,  89,  90,  91,  92,  93,  94,  95,  97,  98,  99, 100,\n",
        "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
        "       116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "       130, 131, 132, 135, 136, 138, 139, 141, 142, 143, 144, 145, 146,\n",
        "       147, 148, 149]),\n",
        "  array([  0,   1,   7,   8,  13,  20,  22,  25,  37,  47,  50,  57,  60,\n",
        "        61,  63,  68,  71,  72,  79,  81,  86,  88,  96, 101, 115, 129,\n",
        "       133, 134, 137, 140]))]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Figure out how to get single row arrays from a dataframe\n",
      "\n",
      "print Xfeatures.take([1,2,24])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    SepalLength  SepalWidth  PetalLength  PetalWidth\n",
        "1           4.9         3.0          1.4         0.2\n",
        "2           4.7         3.2          1.3         0.2\n",
        "24          4.8         3.4          1.9         0.2\n",
        "\n",
        "[3 rows x 4 columns]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# My generic cross validation fn from a DataFrame\n",
      "# NOTE: I'm going to embed random_state = 27, just for variety.\n",
      "\n",
      "def my_cross_validate(X, y, classifier, num_folds, verbose=True) :\n",
      "    \"\"\"This will run your classifer function on /num_folds/ of cross validation, using your feature DataFrame X and your labelled DataFrame Y\"\"\"\n",
      "\n",
      "    # num_folds is the number of folds I want.\n",
      "    \n",
      "    # derive a set of (random) training & test indices\n",
      "    k_fold_indices = KFold( len(X), n_folds=num_folds, indices=True, shuffle=True, random_state=27)\n",
      "    \n",
      "    # Run the classifier now, and tally the scores Im getting.\n",
      "    k_score_total = 0\n",
      "    i = 0\n",
      "    \n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "        \n",
      "        model = classifier(X.take(train_slice),\n",
      "                           y.take(train_slice))\n",
      "        \n",
      "        this_score = model.score(X.take(test_slice),\n",
      "                              y.take(test_slice))\n",
      "        if verbose == True:\n",
      "            print \"Scoring fold\", i, \":\", this_score\n",
      "            i += 1\n",
      "        k_score_total += this_score\n",
      "        \n",
      "    # return the average accuracy having scored on the test slice over all folds\n",
      "    if verbose == True:\n",
      "        print\n",
      "    print \"Output is average of score on all folds :\", (k_score_total / num_folds)\n",
      "    return k_score_total / num_folds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_cross_validate( Xfeatures, ysolutions, KNeighborsClassifier(5).fit, 5, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Scoring fold 0 : 0.966666666667\n",
        "Scoring fold 1 : 0.933333333333\n",
        "Scoring fold 2 : 1.0\n",
        "Scoring fold 3 : 1.0\n",
        "Scoring fold 4 : 0.933333333333\n",
        "\n",
        "Output is average of score on all folds : 0.966666666667\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "0.96666666666666656"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Use your KNN classifier and cross-validation code from (1) and (2) above to determine the optimal value of K (number of nearest neighbors to consult) for this Iris dataset. This hyperparameter will be a number between 1 and 150"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first let me build an iterator, then I'll figure out how to save the values to an array\n",
      "\n",
      "# initialize the accuracy matrix\n",
      "accuracy = np.array([[0,0]])\n",
      "\n",
      "for i in range(1,151):\n",
      "    # always use 5 folds in cross validation\n",
      "    t = my_cross_validate( Xfeatures, ysolutions, KNeighborsClassifier( i ).fit, 5, False)\n",
      "    accuracy = np.append(accuracy, [[ i, t ]], axis=0)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.933333333333\n",
        "Output is average of score on all folds : 0.96\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.96\n",
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds : 0.96\n",
        "Output is average of score on all folds : 0.96\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "Output is average of score on all folds : 0.98\n",
        "Output is average of score on all folds : 0.98\n",
        "Output is average of score on all folds : 0.98\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds : 0.973333333333\n",
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds : 0.973333333333\n",
        "Output is average of score on all folds : 0.973333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds : 0.96\n",
        "Output is average of score on all folds : 0.96\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.96\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.953333333333\n",
        "Output is average of score on all folds : 0.946666666667\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.953333333333\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.96\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.966666666667\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.953333333333\n",
        "Output is average of score on all folds : 0.946666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.946666666667\n",
        "Output is average of score on all folds : 0.946666666667\n",
        "Output is average of score on all folds : 0.94\n",
        "Output is average of score on all folds : 0.94\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.946666666667\n",
        "Output is average of score on all folds : 0.94\n",
        "Output is average of score on all folds : 0.933333333333\n",
        "Output is average of score on all folds : 0.94\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.933333333333\n",
        "Output is average of score on all folds : 0.926666666667\n",
        "Output is average of score on all folds : 0.933333333333\n",
        "Output is average of score on all folds : 0.926666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.926666666667\n",
        "Output is average of score on all folds : 0.92\n",
        "Output is average of score on all folds : 0.913333333333\n",
        "Output is average of score on all folds : 0.913333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.913333333333\n",
        "Output is average of score on all folds : 0.906666666667\n",
        "Output is average of score on all folds : 0.906666666667\n",
        "Output is average of score on all folds : 0.906666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.886666666667\n",
        "Output is average of score on all folds : 0.893333333333\n",
        "Output is average of score on all folds : 0.88\n",
        "Output is average of score on all folds : 0.893333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.88\n",
        "Output is average of score on all folds : 0.893333333333\n",
        "Output is average of score on all folds : 0.893333333333\n",
        "Output is average of score on all folds : 0.9\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.88\n",
        "Output is average of score on all folds : 0.88\n",
        "Output is average of score on all folds : 0.853333333333\n",
        "Output is average of score on all folds : 0.866666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.806666666667\n",
        "Output is average of score on all folds : 0.8\n",
        "Output is average of score on all folds : 0.813333333333\n",
        "Output is average of score on all folds : 0.8\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.733333333333\n",
        "Output is average of score on all folds : 0.74\n",
        "Output is average of score on all folds : 0.733333333333\n",
        "Output is average of score on all folds : 0.74\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.733333333333\n",
        "Output is average of score on all folds : 0.713333333333\n",
        "Output is average of score on all folds : 0.72\n",
        "Output is average of score on all folds : 0.713333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.693333333333\n",
        "Output is average of score on all folds : 0.666666666667\n",
        "Output is average of score on all folds : 0.653333333333\n",
        "Output is average of score on all folds : 0.646666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.573333333333\n",
        "Output is average of score on all folds : 0.546666666667\n",
        "Output is average of score on all folds : 0.533333333333\n",
        "Output is average of score on all folds : 0.533333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.52\n",
        "Output is average of score on all folds : 0.493333333333\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds : 0.48\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.473333333333\n",
        "Output is average of score on all folds : 0.473333333333\n",
        "Output is average of score on all folds : 0.473333333333\n",
        "Output is average of score on all folds : 0.466666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.466666666667\n",
        "Output is average of score on all folds : 0.466666666667\n",
        "Output is average of score on all folds : 0.466666666667\n",
        "Output is average of score on all folds : 0.466666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.453333333333\n",
        "Output is average of score on all folds : 0.44\n",
        "Output is average of score on all folds : 0.42\n",
        "Output is average of score on all folds : 0.42\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.373333333333\n",
        "Output is average of score on all folds : 0.3\n",
        "Output is average of score on all folds : 0.293333333333\n",
        "Output is average of score on all folds : 0.28\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n",
        "Output is average of score on all folds : 0.253333333333\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[   0.            0.        ]\n",
        " [   1.            0.95333333]\n",
        " [   2.            0.93333333]\n",
        " [   3.            0.96      ]\n",
        " [   4.            0.96      ]\n",
        " [   5.            0.96666667]\n",
        " [   6.            0.96      ]\n",
        " [   7.            0.96      ]\n",
        " [   8.            0.97333333]\n",
        " [   9.            0.98      ]\n",
        " [  10.            0.98      ]\n",
        " [  11.            0.98      ]\n",
        " [  12.            0.97333333]\n",
        " [  13.            0.96666667]\n",
        " [  14.            0.97333333]\n",
        " [  15.            0.96666667]\n",
        " [  16.            0.97333333]\n",
        " [  17.            0.96666667]\n",
        " [  18.            0.97333333]\n",
        " [  19.            0.97333333]\n",
        " [  20.            0.97333333]\n",
        " [  21.            0.96666667]\n",
        " [  22.            0.96      ]\n",
        " [  23.            0.96      ]\n",
        " [  24.            0.96      ]\n",
        " [  25.            0.95333333]\n",
        " [  26.            0.95333333]\n",
        " [  27.            0.95333333]\n",
        " [  28.            0.95333333]\n",
        " [  29.            0.94666667]\n",
        " [  30.            0.95333333]\n",
        " [  31.            0.95333333]\n",
        " [  32.            0.95333333]\n",
        " [  33.            0.95333333]\n",
        " [  34.            0.96      ]\n",
        " [  35.            0.95333333]\n",
        " [  36.            0.96666667]\n",
        " [  37.            0.95333333]\n",
        " [  38.            0.95333333]\n",
        " [  39.            0.94666667]\n",
        " [  40.            0.94666667]\n",
        " [  41.            0.94666667]\n",
        " [  42.            0.94      ]\n",
        " [  43.            0.94      ]\n",
        " [  44.            0.94666667]\n",
        " [  45.            0.94      ]\n",
        " [  46.            0.93333333]\n",
        " [  47.            0.94      ]\n",
        " [  48.            0.93333333]\n",
        " [  49.            0.92666667]\n",
        " [  50.            0.93333333]\n",
        " [  51.            0.92666667]\n",
        " [  52.            0.92666667]\n",
        " [  53.            0.92      ]\n",
        " [  54.            0.91333333]\n",
        " [  55.            0.91333333]\n",
        " [  56.            0.91333333]\n",
        " [  57.            0.90666667]\n",
        " [  58.            0.90666667]\n",
        " [  59.            0.90666667]\n",
        " [  60.            0.88666667]\n",
        " [  61.            0.89333333]\n",
        " [  62.            0.88      ]\n",
        " [  63.            0.89333333]\n",
        " [  64.            0.88      ]\n",
        " [  65.            0.89333333]\n",
        " [  66.            0.89333333]\n",
        " [  67.            0.9       ]\n",
        " [  68.            0.88      ]\n",
        " [  69.            0.88      ]\n",
        " [  70.            0.85333333]\n",
        " [  71.            0.86666667]\n",
        " [  72.            0.80666667]\n",
        " [  73.            0.8       ]\n",
        " [  74.            0.81333333]\n",
        " [  75.            0.8       ]\n",
        " [  76.            0.73333333]\n",
        " [  77.            0.74      ]\n",
        " [  78.            0.73333333]\n",
        " [  79.            0.74      ]\n",
        " [  80.            0.73333333]\n",
        " [  81.            0.71333333]\n",
        " [  82.            0.72      ]\n",
        " [  83.            0.71333333]\n",
        " [  84.            0.69333333]\n",
        " [  85.            0.66666667]\n",
        " [  86.            0.65333333]\n",
        " [  87.            0.64666667]\n",
        " [  88.            0.57333333]\n",
        " [  89.            0.54666667]\n",
        " [  90.            0.53333333]\n",
        " [  91.            0.53333333]\n",
        " [  92.            0.52      ]\n",
        " [  93.            0.49333333]\n",
        " [  94.            0.48      ]\n",
        " [  95.            0.48      ]\n",
        " [  96.            0.48      ]\n",
        " [  97.            0.48      ]\n",
        " [  98.            0.48      ]\n",
        " [  99.            0.48      ]\n",
        " [ 100.            0.48      ]\n",
        " [ 101.            0.48      ]\n",
        " [ 102.            0.48      ]\n",
        " [ 103.            0.48      ]\n",
        " [ 104.            0.47333333]\n",
        " [ 105.            0.47333333]\n",
        " [ 106.            0.47333333]\n",
        " [ 107.            0.46666667]\n",
        " [ 108.            0.46666667]\n",
        " [ 109.            0.46666667]\n",
        " [ 110.            0.46666667]\n",
        " [ 111.            0.46666667]\n",
        " [ 112.            0.45333333]\n",
        " [ 113.            0.44      ]\n",
        " [ 114.            0.42      ]\n",
        " [ 115.            0.42      ]\n",
        " [ 116.            0.37333333]\n",
        " [ 117.            0.3       ]\n",
        " [ 118.            0.29333333]\n",
        " [ 119.            0.28      ]\n",
        " [ 120.            0.25333333]\n",
        " [ 121.            0.25333333]\n",
        " [ 122.            0.25333333]\n",
        " [ 123.            0.25333333]\n",
        " [ 124.            0.25333333]\n",
        " [ 125.            0.25333333]\n",
        " [ 126.            0.25333333]\n",
        " [ 127.            0.25333333]\n",
        " [ 128.            0.25333333]\n",
        " [ 129.            0.25333333]\n",
        " [ 130.            0.25333333]\n",
        " [ 131.            0.25333333]\n",
        " [ 132.            0.25333333]\n",
        " [ 133.            0.25333333]\n",
        " [ 134.            0.25333333]\n",
        " [ 135.            0.25333333]\n",
        " [ 136.            0.25333333]\n",
        " [ 137.            0.25333333]\n",
        " [ 138.            0.25333333]\n",
        " [ 139.            0.25333333]\n",
        " [ 140.            0.25333333]\n",
        " [ 141.            0.25333333]\n",
        " [ 142.            0.25333333]\n",
        " [ 143.            0.25333333]\n",
        " [ 144.            0.25333333]\n",
        " [ 145.            0.25333333]\n",
        " [ 146.            0.25333333]\n",
        " [ 147.            0.25333333]\n",
        " [ 148.            0.25333333]\n",
        " [ 149.            0.25333333]\n",
        " [ 150.            0.25333333]]\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print max(accuracy[0::,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.98\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find the indices of elements of x that are in goodvalues.\n",
      "# source: http://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html\n",
      "\n",
      "goodvalues = max(accuracy[0::,1])        # my desired search is on the Max of score column\n",
      "ix = np.in1d(accuracy.ravel(), goodvalues).reshape(accuracy.shape)\n",
      "# ix                                     # produce a boolean mask\n",
      "print np.where(ix)[0]                    # return the first array part, which is the accuracy indices where True\n",
      "\n",
      "optimal_k_values = accuracy[ (np.where(ix)[0]) , 0]     #return column 0, ie the K Neighbors used at this index(ices)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 9 10 11]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print optimal_k_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  9.  10.  11.]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4. Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range of K that you consider interesting. Explain in words what you are seeing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
      "% pylab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: MacOSX\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate the top-level figure for this plot\n",
      "fig = plt.figure(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "majorFormatter = FormatStrFormatter('%1.3f')   # Set the number of decimal places in my y-axis labels\n",
      "majorFormatter\n",
      "\n",
      "majorLocator   = MultipleLocator(10)\n",
      "minorLocator   = MultipleLocator(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate a subplot??\n",
      "ax1 = fig.add_subplot(1,1,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig.suptitle('K neighbors vs accuracy: iris dataset', fontsize = 18)   # Title the figure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "<matplotlib.text.Text at 0x10d0b30d0>"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_axes = plt.gcf().axes           # g_et c_urrent f_igure()\n",
      "for ax in all_axes:\n",
      "    ax.xaxis.set_major_locator(majorLocator)\n",
      "    ax.xaxis.set_minor_locator(minorLocator)\n",
      "    ax.yaxis.set_major_formatter(majorFormatter)                       # set the y-ax to 1 decimal format\n",
      "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():      # then for both x & y axes,\n",
      "        ticklabel.set_fontsize(10)                                      # set the font size\n",
      "        \n",
      "        \n",
      "# Now plot        \n",
      "ax1.scatter(accuracy[1:100,0],\n",
      "            accuracy[1:100,1],\n",
      "            c='b',\n",
      "            marker='o')\n",
      "ax1.set_xlabel(\"chose K neighbors\", fontsize=14)\n",
      "ax1.set_ylabel(\"5-fold CV score\", fontsize=14)\n",
      "\n",
      "# I wanted to draw a red line across the maximum accuracy, but cant figure it out.\n",
      "# ax1.plot(accuracy[1:100,0], max(accuracy[0::,1]), 'r--')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "<matplotlib.text.Text at 0x10d096a50>"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save it out as a file\n",
      "plt.savefig('kfolds-vs-accuracy.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Explain in words what you are seeing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The accuracy of a 5-fold cross validation gets better as you add more neighbors on the iris dataset from 1 to 8. Then the prediction accuracy peaks while using 9-, 10-, or 11-nearest neighboring points."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The accuracy remains fairly good up to the use of 20 nearest points, hovering at 0.973, but then decreases gradually and steadily. By the time you are incorporating over 58 nearest points, the accuracy is destroyed, as you are allowing too many points of non-similar species to affect the outcome of your prediction."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. OPTIONAL BONUS: Using the value of K obtained in (3) above, vary the number of folds used for cross-validation across an interesting range, e.g. [ 2, 3, 5, 6, 10, 15]. How does classifier accuracy vary with the number of folds used? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let me build an iterator again\n",
      "# initialize the accuracy matrix\n",
      "accuracy2 = np.array([[0,0]])\n",
      "\n",
      "for i in [2, 3, 5, 6, 10, 15, 30, 50, 150]:\n",
      "    # always use 10 nearest neighborsn\n",
      "    t = my_cross_validate( Xfeatures, ysolutions, KNeighborsClassifier( 10 ).fit, i, False)\n",
      "    accuracy2 = np.append(accuracy2, [[ i, t ]], axis=0)\n",
      "\n",
      "print accuracy2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds : 0.973333333333\n",
        "Output is average of score on all folds : 0.98\n",
        "Output is average of score on all folds : 0.98\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.98\n",
        "Output is average of score on all folds : 0.966666666667\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "Output is average of score on all folds :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.973333333333\n",
        "[[   0.            0.        ]\n",
        " [   2.            0.96666667]\n",
        " [   3.            0.97333333]\n",
        " [   5.            0.98      ]\n",
        " [   6.            0.98      ]\n",
        " [  10.            0.98      ]\n",
        " [  15.            0.96666667]\n",
        " [  30.            0.97333333]\n",
        " [  50.            0.97333333]\n",
        " [ 150.            0.97333333]]\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print max(accuracy2[0::,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.98\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, the accuracy increases at first, using 2 to 5 folds of the data set. Accuracy peaks at 5 to 10 folds, meaning slices of 30 to 15 rows in each fold.  At peak accuracy, the data was being split into (120 rows train split / 30 rows test) to (135 rows train split / 15 rows test)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By the time you're doing 30 folds, you are training on 145 rows and testing on 5 rows. I imagine that it is starting to overfit and possibly mis-predicting one of the test labels."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yup:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_cross_validate( Xfeatures, ysolutions, KNeighborsClassifier( 10 ).fit, 30, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Scoring fold 0 : 1.0\n",
        "Scoring fold 1 : 0.8\n",
        "Scoring fold 2 : 1.0\n",
        "Scoring fold 3 : 1.0\n",
        "Scoring fold 4 : 1.0\n",
        "Scoring fold 5 : 0.8\n",
        "Scoring fold 6 : 1.0\n",
        "Scoring fold 7 : 1.0\n",
        "Scoring fold 8 : 1.0\n",
        "Scoring fold 9 : 1.0\n",
        "Scoring fold 10 : 1.0\n",
        "Scoring fold 11 : 1.0\n",
        "Scoring fold 12 : 1.0\n",
        "Scoring fold 13 : 1.0\n",
        "Scoring fold 14 : 1.0\n",
        "Scoring fold 15 : 1.0\n",
        "Scoring fold 16 : 1.0\n",
        "Scoring fold 17 : 1.0\n",
        "Scoring fold 18 : 1.0\n",
        "Scoring fold 19 : 1.0\n",
        "Scoring fold"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20 : 1.0\n",
        "Scoring fold 21 : 1.0\n",
        "Scoring fold 22 : 1.0\n",
        "Scoring fold 23 : 1.0\n",
        "Scoring fold 24 : 1.0\n",
        "Scoring fold 25 : 1.0\n",
        "Scoring fold 26 : 1.0\n",
        "Scoring fold 27 : 0.6\n",
        "Scoring fold 28 : 1.0\n",
        "Scoring fold 29 : 1.0\n",
        "\n",
        "Output is average of score on all folds : 0.973333333333\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "0.97333333333333338"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Do you think there exists an optimal number of folds to use for this particular problem? Why or why not?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seems like 5 folds is optimal for cross-validation here. That way is leaving yourself the largest number of test rows (30), while still capturing the advantage gains of a having a train size increase relative to smaller folds like 2 or 3."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}